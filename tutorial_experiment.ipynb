{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kircherlab/MPRAsnakeflow_tutorial/blob/development/tutorial_association.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsBG7lOCPnnE",
        "outputId": "6da1caeb-905a-42f8-843a-54409a379c0f"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOSJecyQPnnC"
      },
      "source": [
        "# MPRAsnakeflow experiment tutorial\n",
        "\n",
        "First we will cover the config file and afterwards we will look at interesting results like the correlation of the DNA and RNA counts among the replicates. This is useful in practice to check if the data preparation went well, because if the resulting data is not correlating between replicates, problems during the experiment will introduce a bias in the results of our analysis that we would like to know about."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAAYJQqv9zIk"
      },
      "source": [
        "## Pre-requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOsEkOFu-MbM"
      },
      "source": [
        "### Docker/uDocker/apptainer\n",
        "\n",
        "When running locally you need to install `docker` or `apptainer`. For running it remotly on google colab `udocker` in colab from github.com/drengskapur/docker-in-colab works nicely.\n",
        "\n",
        "We try to atomatically find out what you need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tutorial_container = \"visze/mprasnakeflow_tutorial:0.1.0\"\n",
        "docker= False\n",
        "apptainer = False\n",
        "\n",
        "docker = !docker --help &>/dev/null; if [ $? -eq 0 ]; then echo 1; else echo 0; fi\n",
        "docker = bool(int(docker[0]))\n",
        "apptainer = !apptainer --help &>/dev/null; if [ $? -eq 0 ]; then echo 1; else echo 0; fi\n",
        "apptainer = bool(int(apptainer[0]))\n",
        "\n",
        "if docker:\n",
        "    print(\"Docker is installed! We will use Docker to run MPRAsnakeflow\")\n",
        "elif apptainer:\n",
        "    print(\"Apptainer is installed! We will use Apptainer to run MPRAsnakeflow\")\n",
        "else:\n",
        "    print(\"Neither Docker nor Apptainer is installed. We assume you run the tutorial on colab and we will install uDocker for colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When neither Docker nor Apptainer is installed we will install udocjer for colab now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSTDSHTN4JJk",
        "outputId": "5c2ad4b0-cc4b-4ced-9bfe-a75960cc36bd"
      },
      "outputs": [],
      "source": [
        "def udocker_init():\n",
        "    import os\n",
        "    if not os.path.exists(\"/home/user\"):\n",
        "        !pip install udocker > /dev/null\n",
        "        !udocker --allow-root install > /dev/null\n",
        "        !useradd -m user > /dev/null\n",
        "    print(f'Docker-in-Colab 1.1.0\\n')\n",
        "    print(f'Usage:     udocker(\"--help\")')\n",
        "    print(f'Examples:  https://github.com/indigo-dc/udocker?tab=readme-ov-file#examples')\n",
        "\n",
        "    def execute(command: str):\n",
        "        user_prompt = \"\\033[1;32muser@pc\\033[0m\"\n",
        "        print(f\"{user_prompt}$ udocker {command}\")\n",
        "        !su - user -c \"udocker $command\"\n",
        "\n",
        "    return execute\n",
        "\n",
        "if not docker and not apptainer:\n",
        "    udocker = udocker_init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a general function to run our MPRAsnakeflow tutorial container that will check if docker, apptainer or uDocker has to be run. It will also bind your data directory `${{PWD}}/MPRAsnakeflow_tutorial` (will be dowloaded later) to `/data/run` within the container and defines this as working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def runContainer(command):\n",
        "    user_prompt = \"\\033[1;32muser@pc\\033[0m\"\n",
        "    if docker:\n",
        "        print(f\"{user_prompt}$ docker run -v=${{PWD}}/MPRAsnakeflow_tutorial:/data/run --workdir /data/run {tutorial_container} {command}\")\n",
        "        !docker run -v=${{PWD}}/MPRAsnakeflow_tutorial:/data/run --workdir /data/run {tutorial_container} {command}\n",
        "    elif apptainer:\n",
        "        print(f\"apptainer run -B=${{PWD}}/MPRAsnakeflow_tutorial:/data/run --cwd /data/run mprasnakeflow_tutorial.sif {command}\")\n",
        "        !apptainer run -B=${{PWD}}/MPRAsnakeflow_tutorial:/data/run --cwd /data/run mprasnakeflow_tutorial.sif {command}\n",
        "    else:\n",
        "        udocker(f\"run -v=${{PWD}}/MPRAsnakeflow_tutorial:/data/run --workdir /data/run mprasnakeflow_tutorial {command}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb0rhjfo8dbA"
      },
      "source": [
        "### Test data\n",
        "\n",
        "The data used in this tutorial is present in the github repository. We will dowload it using git so that it is also present within a colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGLsBxpyst9V"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "git clone https://github.com/kircherlab/MPRAsnakeflow_tutorial.git\n",
        "cd MPRAsnakeflow_tutorial\n",
        "git checkout development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WYuqwGr-fEp"
      },
      "source": [
        "### snakemake\n",
        "\n",
        "MPRAsnakeflow and its software dependencies is packed in the official snakemake v8.16.0 container and you can find it on dockerhub wih thetag [`visze/mprasnakeflow_tutorial:0.1.0`](https://hub.docker.com/layers/visze/mprasnakeflow_tutorial/0.1.0/images/sha256-f4f75aae0ceba517d363307f176a83b1414c74086d99cbd5e90196b7e2ace179?context=explore)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZv9f_eu4bB9",
        "outputId": "67fa0e9c-386e-454a-c88d-11ce125ee5c3"
      },
      "outputs": [],
      "source": [
        "if docker:\n",
        "    print(f\"docker pull {tutorial_container}\")\n",
        "    !docker pull \"{tutorial_container}\"\n",
        "    print(f\"docker create --name=mprasnakeflow_tutorial {tutorial_container}\")\n",
        "    !docker create --name=mprasnakeflow_tutorial \"{tutorial_container}\" > /dev/null\n",
        "elif apptainer:\n",
        "    print(f\"apptainer pull mprasnakeflow_tutorial.sif docker://{tutorial_container}\")\n",
        "    !apptainer pull mprasnakeflow_tutorial.sif docker://{tutorial_container} > /dev/null\n",
        "else:\n",
        "    udocker(f\"pull {tutorial_container}\")\n",
        "    udocker(f\"create --name=mprasnakeflow_tutorial {tutorial_container}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYhKnwlV-orz"
      },
      "source": [
        "Try to run `snakemake --version` in docker:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jQi5e3634sDP",
        "outputId": "844eb31f-20d4-463a-ef20-6c6c3b013e7a"
      },
      "outputs": [],
      "source": [
        "runContainer(\"snakemake --version\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment Workflow\n",
        "\n",
        "For the experiment step, where the counts per oligo are calculated, we need all the files in the `example_data/counts` folder, as well as the config file and the barcode assignment file, which is the output of the assignment step (but also stored under `example_data/counts`).\n",
        "\n",
        "We investigated the assignment file in the association tutorial. This table is now used to count the number of observed barcodes for each target sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can take a look at the input files, to understand what we later have to gve the MPRAsnbakeflow pipeline via a config file. Each count experiment, in our case, is described using three files (the paths of which are in the `experiment.csv` file): forward reads, reverse reads, and UMIs. Note that the UMIs are optional, and serve to deduplicate barcodes with overdispersed counts due to preferential amplification related to GC content or library preparation steps. From one of the UMI read files, we can see that indeed our UMI length is 16:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nAverage length of a UMI:\")\n",
        "!zcat \"MPRAsnakeflow_tutorial/example_data/counts/dna-1_S1_R2_001.fastq.gz\" | awk 'NR % 4 == 2 {{sum += length($$0)}} END {{print sum*4/NR}}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can lso check the length of the barcode, which should be 15:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nAverage length of a barcode:\")\n",
        "!zcat \"MPRAsnakeflow_tutorial/example_data/counts/dna-1_S1_R1_001.fastq.gz\" | awk 'NR % 4 == 2 {{sum += length($$0)}} END {{print sum*4/NR}}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KqdtmOb_gHg"
      },
      "source": [
        "## Run MPRAsnakeflow\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Snakemake\n",
        "\n",
        "Before we come to more MPRAsnakeflow pipeline specific things we quickly want to introduce the snakemake workflow management system. A workflow management system, also like nextflow or cwl, is a tool to create reproducible and scalable data analyses. Snakemake workflows are described via a human readable, Python based language. They can be seamlessly scaled to server, cluster, grid and cloud environments, without the need to modify the workflow definition. Finally, Snakemake workflows can entail a description of required software, which will be automatically deployed to any execution environment.\n",
        "\n",
        "Each step in snakemake is defined as a `rule`. Which has a `input`, `output` and a mostly `shell` command. The `input` and `output` are files that are used as input and output for the rule. The `shell` command is the command that is executed to create the output file from the input file. There are other commands like `conda`, `params`, `log`, `threads`, `resources` that can be used to define the rule.\n",
        "\n",
        "E.g. here is an example rule `assigned_counts_combine_replicates` of MPRAsnakeflow, which combines counts of replicates into one final count. In short: merging counts of replicates. The ruzle takes as ainput a tab separated file with all counts in it per condition. And the python script that will merge it `combine_replicates.py`. Path names in curly brackets like  `{project}` or `{assignment}` is a wildcard and the name will be the project, assignment name etc that is configured in the config files.  Finally the `shell` command takes the python script, the inputs and runs it creating the output and logs.\n",
        "\n",
        "```python\n",
        "rrule assigned_counts_combine_replicates:\n",
        "    \"\"\"\n",
        "    Combine replicates of master table by summing counts up and using also the average.\n",
        "    \"\"\"\n",
        "    conda:\n",
        "        \"../envs/python3.yaml\"\n",
        "    input:\n",
        "        master_table=\"results/experiments/{project}/assigned_counts/{assignment}/{config}/{condition}_{allreps_or_threshold}_merged.tsv.gz\",\n",
        "        script=getScript(\"count/combine_replicates.py\"),\n",
        "    output:\n",
        "        \"results/experiments/{project}/assigned_counts/{assignment}/{config}/{condition}_{allreps_or_threshold}_merged.combined.tsv.gz\",\n",
        "    params:\n",
        "        label_file=lambda wc: (\n",
        "            \"--labels %s\" % config[\"experiments\"][wc.project][\"label_file\"]\n",
        "            if \"label_file\" in config[\"experiments\"][wc.project]\n",
        "            else \"\"\n",
        "        ),\n",
        "    log:\n",
        "        temp(\n",
        "            \"results/logs/assigned_counts/combine_replicates.{project}.{condition}.{config}.{assignment}.{allreps_or_threshold}.log\"\n",
        "        ),\n",
        "    shell:\n",
        "        \"\"\"\n",
        "        python {input.script} \\\n",
        "        --input {input.master_table} \\\n",
        "        {params.label_file} \\\n",
        "        --output {output}  &> {log}\n",
        "        \"\"\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When running snakemake you need to specify where your worflow is, basically the main `Snakefile` of it. By default, Snakemake will search for ‘Snakefile’, ‘snakefile’, ‘workflow/Snakefile’, ‘workflow/snakefile’ beneath the current working directory, in this order. Then you do not have to use this command. But practically your workflow, here MPRAsnakeflow, might live somewhere else and you want to run the workflow in a different directory where you want to produce results. Then you need to specify the `--snakefile` parameter to the MPRAsnakeflow file in `workflow/Snakefile`. Otherwise you ahve to check/copy the workflow in every \"run\" rirectory which is not practically. Usually you start snakemake in the directory where you want to produce results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The config file\n",
        "\n",
        "The heart of your workflow run is the config file. You can specify it via `--configfile`. It is in `yaml` or `json` format. It contains all the parameters and input files that are used in the workflow.\n",
        "\n",
        "The config file has many parameters. But most of them have a default well, based on best practice and you don't have to specify them. But you can overwrite them if you want. Config files are first validated using json schema. If your config file is not correct MPRAsnakeflow will tell you what is missing or wrong and stop. Naming, parameters etc. might change from MPRAsnakeflow version and you might have to update your config file if you run a new version of MPRAsnakeflow. An extensive documentation of the config file can be found in the [MPRAsnakeflow documentation](https://mprasnakeflow.readthedocs.io/en/development/config.html).\n",
        "\n",
        "Here is the config file that we will use for running the experiment tutorial.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```yaml\n",
        "---\n",
        "experiments:\n",
        "  experimentMPRAworkshop:\n",
        "    bc_length: 15\n",
        "    umi_length: 16\n",
        "    data_folder: example_data/counts\n",
        "    experiment_file: example_data/experiment.csv\n",
        "    assignments:\n",
        "      MPRAworkshop:\n",
        "        type: file\n",
        "        assignment_file: example_data/assignment/assignment_barcodes.default.tsv.gz\n",
        "    label_file: example_data/design/workshop_labels.tsv\n",
        "    configs:\n",
        "      default: {}\n",
        "      tutorialConfig:\n",
        "        filter:\n",
        "          bc_threshold: 5\n",
        "          DNA:\n",
        "            min_counts: 1\n",
        "          RNA:\n",
        "            min_counts: 1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following block shows the part of the config file that concerns the experiment part. Since assignment and experiment part can be run independently the `bc_length` needs to be set again.\n",
        "\n",
        "The `experiment_file` holds the path to the file of the experiment table (i.e. condition, replicate and name of read files given)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!sed -n '/experiments:/,$p' \"{data_dir}/workshop_config.yaml\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because we run the experiment workflow we start with `experiments`. Then a list with possible names of experiments will follow. Here we have just one: `experimentMPRAworkshop`. The whole config file has the minimal information, which is needed by MPRAsnakeflow (except for `configs`, see later). This is the barcode length `bc_length` and the UMI length `umi_length` which we calculated previously. Then a link to folder `data_folder` where all fastqs of the experiment are. What conditions, replicates and belonging fastq files we have is stored in the the `experiment_file`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a sanity check and to understand where these values come from, we will take a look at if the information matches our input files. We used 15 bp adapters for this MPRA experiment, which were added at both ends of each designed oligo. The ``alignment_start`` configuration refers to these adapters as our actual target sequences only starts after the 15 bp of adapter sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "adapter_length=15\n",
        "\n",
        "print(\"\\nAverage length of a barcode:\")\n",
        "!zcat \"MPRAsnakeflow_tutorial/example_data/assignment/assoc_bc.fastq.gz\" | awk 'NR % 4 == 2 {{sum += length($$0)}} END {{print sum*4/NR}}'\n",
        "\n",
        "print(\"\\nAverage length of a target sequence (oligo length - 2 x adapter):\")\n",
        "seq_length_with_bc = !cat \"MPRAsnakeflow_tutorial/example_data/design/workshop_design.fa\" | awk 'NR % 4 == 2 {{sum +=length($$0)}} END {{print sum*4/NR}}'\n",
        "seq_length_with_bc = int(seq_length_with_bc[0])\n",
        "seq_length = seq_length_with_bc - 2*adapter_length\n",
        "print(seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MPRAsnakeflow tutorial profile\n",
        "\n",
        "Snakemake can make use of profiles to pre-configure command-line-interfaces as well as ressources and number of threads as default or per rule. A profile has to be stored (on Linux) in the folder `$HOME/.config/snakemake` or `/etc/xdg/snakemake`. It can be activated by using the `--profile` option in the snakemake command. In addition you can set an environment variable `SNAKEMAKE_PROFILE`, e.g. by specifying export `SNAKEMAKE_PROFILE=myprofile` in your `~/.bashrc` to use the profile by default. In addition a specific workflow profile can be set using `--workflow-profile path_to_your_profile`. E.g. we pre-defined a [workflow profile for MPRAsnakeflow](https://github.com/kircherlab/MPRAsnakeflow/blob/development/profiles/default/config.yaml) adding ressources to each rule with some additional commands for the [snakemake excecutor plugin slum](https://snakemake.github.io/snakemake-plugin-catalog/plugins/executor/slurm.html).\n",
        "\n",
        "For more information on snakemake using profiles please have a look [snakemke profile documentation](https://snakemake.readthedocs.io/en/stable/executing/cli.html#profiles)\n",
        "\n",
        "For the MPRAsnakeflow tutorial we will use the profile `mprasnakeflow` which is stored in the folder `/etc/xdg/snakemake` within the container and the `SNAKEMAKE_PROFILE=mprasnakeflow` is already set. Have a look at the variable and the profile:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runContainer(\"cat /etc/xdg/snakemake/mprasnakeflow/config.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You see that we already defined where the MPRASsnkeflow `Snakefile` is and `--snakefile` is not necessary. Also all software packages are installed alrady in the container using conda and we enable this software deployment method and tell snakemake where the conda environments live (the default will be your exceuction folder under `.snamemake/conda`). Also the `--cores/-c` option is not necessary anymore and snakemake just needs your configuration file of the workflow using the command `--configfile`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the workflow\n",
        "\n",
        "First we run a dry-run to see what will be executed using `-n` and `--quiet rules` to see only the overview of excecuted rules and not each rule command individually. The most important part is setting the config file via `-configfile assignment_config.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXlOomWL5Am2",
        "outputId": "5c32a998-eaef-426e-ccc8-8102d2487950"
      },
      "outputs": [],
      "source": [
        "# MPRAsnakeflow_tutorial must be accessable and writable for all (and docker)\n",
        "!chmod ugo+rwx MPRAsnakeflow_tutorial\n",
        "# Run MPRAsnakeflow\n",
        "runContainer(\"snakemake --configfile config_experiment.yaml -n --quiet rules\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You see a list of rules and how often this rule is executed debending on the input file. E.g. it is possible to you input fastq file into `n` via the rule `assignment_fastq_split` using the option `split_number` in the config file (it is commented out right now). Then rules afterwards, like `assignment_getBCs` will be executed `n` times. Tis behaviour is nice for parallelisation especially on a HPC system where you have multiple nodes available. \n",
        "\n",
        "A short summary of each rule is in the [MPRAsnakeflow documentation](https://mprasnakeflow.readthedocs.io/en/latest/assignment.html#rules).\n",
        "\n",
        "Now let's run snakemake using 10 cores (BWA can be parallized). When you add the `-p` flag you will see the exact code that is executed in each rule. But we ommit this here beacuse it is a lot of output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNESKLR_UkLV"
      },
      "outputs": [],
      "source": [
        "runContainer(\"snakemake --configfile config_experiment.yaml -c 10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment results\n",
        "\n",
        "Let's take a look at the files in the experiment results folder!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_dir = \"MPRAsnakeflow_tutorial/results/experiments\"\n",
        "!ls -R \"{results_dir}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can take a look at the amount of barcodes that have been removed due to UMI collision, by checking how many unique BC x UMI combinations we have in our data. (We are now checking the RNA counts in replicate 1, but we should look at both DNA and RNA counts in all three replicates.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"First few lines of a count file, where column 1 contains the barcode, 2 the UMI and 3 the count.\")\n",
        "!zcat \"{results_dir}\"/experimentMPRAworkshop/counts/HepG2_1_RNA_filtered_counts.tsv.gz | awk 'NR <= 10 {{print}}'\n",
        "\n",
        "print(\"\\nAmount of total BC x UMI combinations:\")\n",
        "!zcat \"{results_dir}\"/experimentMPRAworkshop/counts/HepG2_1_RNA_filtered_counts.tsv.gz | wc -l\n",
        "\n",
        "print(\"\\nAmount of duplicate BC x UMI combinations (the file is sorted):\")\n",
        "!zcat \"{results_dir}\"/experimentMPRAworkshop/counts/HepG2_1_RNA_filtered_counts.tsv.gz | uniq -d | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are no collisions, indicating that this subset of the data is of high quality. Great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The count files are then joined with the assignment file (the output of the assignment step) to assign counts to oligos. The barcode counts are then aggregated over the oligos. This is done within MPRAsnakeflow with additional filter steps, but to give you a feeling of what's happening we give you some simplified code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts_rep1 = os.path.join(results_dir, \"experimentMPRAworkshop/assigned_counts/MPRAworkshop/HepG2_1.merged.config.tutorialConfig.tsv.gz\")\n",
        "assignment = \"MPRAsnakeflow_tutorial/example_data/assignment/assignment_barcodes.default.tsv.gz\"\n",
        "\n",
        "print(\"Joining the assignment and the counts of replicate 1:\\n\\nBarcode\\toligo\\tDNA\\tRNA\")\n",
        "!join <(zcat {assignment}) <(zcat {counts_rep1}) -t $'\\t' | cut -f 1,2,5-6 | awk 'NR <= 10 {{print}}'\n",
        "\n",
        "print(\"\\nAggregating the barcodes over oligos and the counts of replicate 1:\\n\\noligo\\tDNA\\tRNA\")\n",
        "!join <(zcat {assignment}) <(zcat {counts_rep1}) -t $'\\t' | cut -f 1,2,5-6 | sort -k2,2 | \\\n",
        " awk -v OFS=\"\\t\" '{{if ($$2 == prev) {{dna += $$3; rna += $$4}} else {{ if (NR > 1) print prev,dna,rna; prev=$$2; dna=$$3;rna=$$4}}}}' | awk 'NR <= 10 {{print}}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next steps, barcodes are already aggregated to their oligos/targets.  \n",
        "  \n",
        "We will have a look at the correlation plots between the replicates for DNA and RNA now. Typically, we will sequence RNA counts deeper than DNA -- because of the larger dynamic range of RNA. We therefore expect that the correlation of RNA counts is higher than that of the DNA. Our example data shows this trend as well.\n",
        "\n",
        "We have a correlation of DNA counts per insert between the replicates of 0.27 and 0.31. This correlation is for a subset of the complete MPRA experiment. The shown output uses the user set minThreshold for removing barcodes with too few counts. In order to see the influence of the parameter another plot is generated without this threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the threshold of 5 barcodes per oligo and at least one DNA and RNA count\n",
        "- DNA correlation: 0.28 - 0.31\n",
        "- RNA correlation: 0.68 - 0.70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(cv2.__version__)\n",
        "dna_pairwise = cv2.imread(f'{results_dir}/experimentMPRAworkshop/statistic/assigned_counts/MPRAworkshop/tutorialConfig/HepG2_DNA_pairwise_minThreshold.png')\n",
        "\n",
        "dna_pairwise_resize = cv2.resize(dna_pairwise, (600, 1000))\n",
        "\n",
        "plt.imshow(dna_pairwise_resize)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rna_pairwise_no_thresh = cv2.imread(f'{results_dir}/experimentMPRAworkshop/statistic/assigned_counts/MPRAworkshop/tutorialConfig/HepG2_RNA_pairwise.png')\n",
        "\n",
        "rna_pairwise_no_thresh_resize = cv2.resize(rna_pairwise_no_thresh, (600, 1000))\n",
        "\n",
        "plt.imshow(rna_pairwise_no_thresh_resize)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following two figures you can see that this trend is continues for a threshold of 10 barcodes per insert.\n",
        "- DNA correlation: 0.31 - 0.39\n",
        "- RNA correlation: 0.79 - 0.80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dna_pairwise_no_thresh = cv2.imread(f'{results_dir}/experimentMPRAworkshop/statistic/assigned_counts/MPRAworkshop/default/HepG2_DNA_pairwise_minThreshold.png')\n",
        "\n",
        "dna_pairwise_no_thresh_resize = cv2.resize(dna_pairwise_no_thresh, (600, 1000))\n",
        "\n",
        "plt.imshow(dna_pairwise_no_thresh_resize)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rna_pairwise_no_thresh = cv2.imread(f'{results_dir}/experimentMPRAworkshop/statistic/assigned_counts/MPRAworkshop/default/HepG2_RNA_pairwise_minThreshold.png')\n",
        "\n",
        "rna_pairwise_no_thresh_resize = cv2.resize(rna_pairwise_no_thresh, (600, 1000))\n",
        "\n",
        "plt.imshow(rna_pairwise_no_thresh_resize)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even though it is a small example, the minimal barcode count threshold shows a clear effect on correlation. However, we also note that we are losing a proprotion of oligos with these strict filters and thereby limit the conclusions that we can draw from the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we want go through the final output of MPRAsnakeflow: the count table of sequences and barcodes together with their aggregated log2 values. Note that there are no statistics calculated at this step yet, the table doesn't say anything about certainty/variance of the activity. The log2 value refers to the log2 ratio of RNA counts over DNA counts for each oligo, which is a measurement of the activity of the target sequence. More on this in the statistical analysis tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " !zcat {results_dir}/experimentMPRAworkshop/assigned_counts/MPRAworkshop/tutorialConfig/HepG2_allreps_merged.tsv.gz | awk 'NR <= 10 {{print}}'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "32PHp-vU99x0",
        "6GilAsqZ4t9r"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
